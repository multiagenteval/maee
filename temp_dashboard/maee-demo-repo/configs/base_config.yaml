dataset:
  name: "mnist"
  type: "classification"
  params:
    batch_size: 32
    train_path: "data/raw/mnist/train"
    test_path: "data/raw/mnist/test"

model:
  name: "baseline_cnn"
  type: "pytorch"
  params:
    input_shape: [1, 28, 28]
    hidden_dims: [32, 64]
    num_classes: 10
    learning_rate: 0.001
    dropout_rate: 0.5

training:
  epochs: 10
  optimizer:
    name: "adam"
    params:
      lr: 0.001
      weight_decay: 0.0001
  scheduler:
    name: "step_lr"
    params:
      step_size: 5
      gamma: 0.1
  early_stopping:
    patience: 3
    min_delta: 0.001
  adversarial:
    enabled: true
    epsilon: 0.3

data:
  train:
    path: "data/raw/mnist/train"
    batch_size: 32
    shuffle: true
  val:
    path: "data/raw/mnist/val"
    batch_size: 32
    shuffle: false
  test:
    path: "data/raw/mnist/test"
    batch_size: 32
    shuffle: false

metrics:
  version: "v1"
  primary:
    - name: "accuracy"
      threshold: 0.70
    - name: "f1"
      threshold: 0.65
  secondary:
    - name: "precision"
      threshold: 0.60
    - name: "recall"
      threshold: 0.60

tracking:
  log_confusion_matrix: true

eval:
  - name: "mnist_test"
    version: "v1"
    description: "Standard MNIST test set"
  - name: "mnist_balanced"
    version: "v1"
    description: "Class-balanced MNIST test set"
  - name: "mnist_noisy"
    version: "v1" 
    description: "MNIST test set with added noise"
  - name: "mnist_adversarial"
    version: "v1"
    description: "MNIST test set with FGSM adversarial attacks"
    params:
      epsilon: 0.3  # Perturbation magnitude 